{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozA32XV19SZJ",
        "outputId": "bbb14d36-4647-460a-fd45-6c34c5d51f3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "epochs=[4]#4,6,8\n",
        "batch_size=[4,8,12]\n",
        "optimizador=[\"Adam\",\"SGD\",\"Adagrad\"]\n",
        "capas=[3,4,5]\n",
        "\n",
        "#carga datos\n",
        "drive.mount('/content/drive')\n",
        "train_dir = '/content/drive/MyDrive/Colab Notebooks/fotos_tiempo/train'\n",
        "valid_dir = '/content/drive/MyDrive/Colab Notebooks/fotos_tiempo/valid'\n",
        "test_dir = '/content/drive/MyDrive/Colab Notebooks/fotos_tiempo/test'\n",
        "\n",
        "#transformaciones\n",
        "transform = transforms.Compose([\n",
        "              transforms.Resize((224, 224)),\n",
        "              transforms.ToTensor(),\n",
        "              transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "          ])\n",
        "\n",
        "\n",
        "train_dataset = ImageFolder(train_dir, transform=transform)\n",
        "valid_dataset = ImageFolder(valid_dir, transform=transform)\n",
        "test_dataset = ImageFolder(test_dir, transform=transform)\n",
        "\n",
        "dfError = pd.DataFrame(columns=[\"epocas\", \"batch\",\"optimizador\",\"capas\",\"accuracy\"])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqNi2duo9SZL",
        "outputId": "a96a8192-0d7b-4c13-b172-6c7ca0c43ce8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "optimizador:\n",
            "Epoch 1/4, Loss: 2.3559802919626236\n",
            "Epoch 2/4, Loss: 1.816244455985725\n",
            "Epoch 3/4, Loss: 1.4159871148876846\n",
            "Epoch 4/4, Loss: 1.0714307319722138\n",
            "Accuracy on validation set: 0.4015151515151515\n",
            "Evaluacion final\n",
            "epocas: 4\n",
            "batch_size: 4\n",
            "optimizador: Adam\n",
            "Capas: 3\n",
            "Final accuracy on test set: 0.42424242424242425\n",
            "  epocas batch optimizador capas  accuracy\n",
            "0      4     4        Adam     3  0.424242\n",
            "optimizador:\n",
            "Epoch 1/4, Loss: 2.3614249732345343\n",
            "Epoch 2/4, Loss: 2.1860689111053944\n",
            "Epoch 3/4, Loss: 2.0609410610049963\n",
            "Epoch 4/4, Loss: 1.9263165909796953\n",
            "Accuracy on validation set: 0.3484848484848485\n",
            "Evaluacion final\n",
            "epocas: 4\n",
            "batch_size: 4\n",
            "optimizador: Adam\n",
            "Capas: 4\n",
            "Final accuracy on test set: 0.3106060606060606\n",
            "  epocas batch optimizador capas  accuracy\n",
            "0      4     4        Adam     3  0.424242\n",
            "1      4     4        Adam     4  0.310606\n",
            "optimizador:\n",
            "Epoch 1/4, Loss: 2.406544029712677\n",
            "Epoch 2/4, Loss: 2.32377777248621\n",
            "Epoch 3/4, Loss: 2.2507953103631735\n",
            "Epoch 4/4, Loss: 2.143438382074237\n",
            "Accuracy on validation set: 0.17424242424242425\n",
            "Evaluacion final\n",
            "epocas: 4\n",
            "batch_size: 4\n",
            "optimizador: Adam\n",
            "Capas: 5\n",
            "Final accuracy on test set: 0.17424242424242425\n",
            "  epocas batch optimizador capas  accuracy\n",
            "0      4     4        Adam     3  0.424242\n",
            "1      4     4        Adam     4  0.310606\n",
            "2      4     4        Adam     5  0.174242\n",
            "optimizador:\n",
            "Epoch 1/4, Loss: 2.3709328584372997\n",
            "Epoch 2/4, Loss: 2.10000916197896\n",
            "Epoch 3/4, Loss: 1.9146921038627625\n",
            "Epoch 4/4, Loss: 1.6084706196561456\n",
            "Accuracy on validation set: 0.3787878787878788\n",
            "Evaluacion final\n",
            "epocas: 4\n",
            "batch_size: 4\n",
            "optimizador: SGD\n",
            "Capas: 3\n",
            "Final accuracy on test set: 0.45454545454545453\n",
            "  epocas batch optimizador capas  accuracy\n",
            "0      4     4        Adam     3  0.424242\n",
            "1      4     4        Adam     4  0.310606\n",
            "2      4     4        Adam     5  0.174242\n",
            "3      4     4         SGD     3  0.454545\n",
            "optimizador:\n",
            "Epoch 1/4, Loss: 2.399989776313305\n",
            "Epoch 2/4, Loss: 2.3954503387212753\n",
            "Epoch 3/4, Loss: 2.391731183975935\n",
            "Epoch 4/4, Loss: 2.382608000189066\n",
            "Accuracy on validation set: 0.10606060606060606\n",
            "Evaluacion final\n",
            "epocas: 4\n",
            "batch_size: 4\n",
            "optimizador: SGD\n",
            "Capas: 4\n",
            "Final accuracy on test set: 0.09090909090909091\n",
            "  epocas batch optimizador capas  accuracy\n",
            "0      4     4        Adam     3  0.424242\n",
            "1      4     4        Adam     4  0.310606\n",
            "2      4     4        Adam     5  0.174242\n",
            "3      4     4         SGD     3  0.454545\n",
            "4      4     4         SGD     4  0.090909\n",
            "optimizador:\n",
            "Epoch 1/4, Loss: 2.398960195481777\n",
            "Epoch 2/4, Loss: 2.3994298987090588\n",
            "Epoch 3/4, Loss: 2.3981661051511765\n",
            "Epoch 4/4, Loss: 2.3960094787180424\n",
            "Accuracy on validation set: 0.17424242424242425\n",
            "Evaluacion final\n",
            "epocas: 4\n",
            "batch_size: 4\n",
            "optimizador: SGD\n",
            "Capas: 5\n",
            "Final accuracy on test set: 0.17424242424242425\n",
            "  epocas batch optimizador capas  accuracy\n",
            "0      4     4        Adam     3  0.424242\n",
            "1      4     4        Adam     4  0.310606\n",
            "2      4     4        Adam     5  0.174242\n",
            "3      4     4         SGD     3  0.454545\n",
            "4      4     4         SGD     4  0.090909\n",
            "5      4     4         SGD     5  0.174242\n",
            "optimizador:\n",
            "Epoch 1/4, Loss: 2.2760281693190336\n",
            "Epoch 2/4, Loss: 1.5394748784601688\n",
            "Epoch 3/4, Loss: 1.0608368176035583\n",
            "Epoch 4/4, Loss: 0.8267591886688024\n",
            "Accuracy on validation set: 0.45454545454545453\n",
            "Evaluacion final\n",
            "epocas: 4\n",
            "batch_size: 4\n",
            "optimizador: Adagrad\n",
            "Capas: 3\n",
            "Final accuracy on test set: 0.45454545454545453\n",
            "  epocas batch optimizador capas  accuracy\n",
            "0      4     4        Adam     3  0.424242\n",
            "1      4     4        Adam     4  0.310606\n",
            "2      4     4        Adam     5  0.174242\n",
            "3      4     4         SGD     3  0.454545\n",
            "4      4     4         SGD     4  0.090909\n",
            "5      4     4         SGD     5  0.174242\n",
            "6      4     4     Adagrad     3  0.454545\n",
            "optimizador:\n",
            "Epoch 1/4, Loss: 2.350841026753187\n",
            "Epoch 2/4, Loss: 2.0127182882279158\n",
            "Epoch 3/4, Loss: 1.6263064546510577\n",
            "Epoch 4/4, Loss: 1.3697339948266745\n",
            "Accuracy on validation set: 0.4696969696969697\n",
            "Evaluacion final\n",
            "epocas: 4\n",
            "batch_size: 4\n",
            "optimizador: Adagrad\n",
            "Capas: 4\n",
            "Final accuracy on test set: 0.4393939393939394\n",
            "  epocas batch optimizador capas  accuracy\n",
            "0      4     4        Adam     3  0.424242\n",
            "1      4     4        Adam     4  0.310606\n",
            "2      4     4        Adam     5  0.174242\n",
            "3      4     4         SGD     3  0.454545\n",
            "4      4     4         SGD     4  0.090909\n",
            "5      4     4         SGD     5  0.174242\n",
            "6      4     4     Adagrad     3  0.454545\n",
            "7      4     4     Adagrad     4  0.439394\n",
            "optimizador:\n",
            "Epoch 1/4, Loss: 2.4172272384166718\n",
            "Epoch 2/4, Loss: 2.1778896916657686\n",
            "Epoch 3/4, Loss: 1.8051309967413545\n",
            "Epoch 4/4, Loss: 1.535445953020826\n",
            "Accuracy on validation set: 0.42424242424242425\n",
            "Evaluacion final\n",
            "epocas: 4\n",
            "batch_size: 4\n",
            "optimizador: Adagrad\n",
            "Capas: 5\n",
            "Final accuracy on test set: 0.36363636363636365\n",
            "  epocas batch optimizador capas  accuracy\n",
            "0      4     4        Adam     3  0.424242\n",
            "1      4     4        Adam     4  0.310606\n",
            "2      4     4        Adam     5  0.174242\n",
            "3      4     4         SGD     3  0.454545\n",
            "4      4     4         SGD     4  0.090909\n",
            "5      4     4         SGD     5  0.174242\n",
            "6      4     4     Adagrad     3  0.454545\n",
            "7      4     4     Adagrad     4  0.439394\n",
            "8      4     4     Adagrad     5  0.363636\n",
            "optimizador:\n",
            "Epoch 1/4, Loss: 2.4542653299868107\n",
            "Epoch 2/4, Loss: 1.7952189929783344\n",
            "Epoch 3/4, Loss: 1.2795073511078954\n",
            "Epoch 4/4, Loss: 0.8968720994889736\n",
            "Accuracy on validation set: 0.5\n",
            "Evaluacion final\n",
            "epocas: 4\n",
            "batch_size: 8\n",
            "optimizador: Adam\n",
            "Capas: 3\n",
            "Final accuracy on test set: 0.49242424242424243\n",
            "  epocas batch optimizador capas  accuracy\n",
            "0      4     4        Adam     3  0.424242\n",
            "1      4     4        Adam     4  0.310606\n",
            "2      4     4        Adam     5  0.174242\n",
            "3      4     4         SGD     3  0.454545\n",
            "4      4     4         SGD     4  0.090909\n",
            "5      4     4         SGD     5  0.174242\n",
            "6      4     4     Adagrad     3  0.454545\n",
            "7      4     4     Adagrad     4  0.439394\n",
            "8      4     4     Adagrad     5  0.363636\n",
            "9      4     8        Adam     3  0.492424\n",
            "optimizador:\n",
            "Epoch 1/4, Loss: 2.3788602724671364\n",
            "Epoch 2/4, Loss: 2.091555744409561\n",
            "Epoch 3/4, Loss: 1.967020858079195\n",
            "Epoch 4/4, Loss: 1.552494216710329\n",
            "Accuracy on validation set: 0.4166666666666667\n",
            "Evaluacion final\n",
            "epocas: 4\n",
            "batch_size: 8\n",
            "optimizador: Adam\n",
            "Capas: 4\n",
            "Final accuracy on test set: 0.4166666666666667\n",
            "   epocas batch optimizador capas  accuracy\n",
            "0       4     4        Adam     3  0.424242\n",
            "1       4     4        Adam     4  0.310606\n",
            "2       4     4        Adam     5  0.174242\n",
            "3       4     4         SGD     3  0.454545\n",
            "4       4     4         SGD     4  0.090909\n",
            "5       4     4         SGD     5  0.174242\n",
            "6       4     4     Adagrad     3  0.454545\n",
            "7       4     4     Adagrad     4  0.439394\n",
            "8       4     4     Adagrad     5  0.363636\n",
            "9       4     8        Adam     3  0.492424\n",
            "10      4     8        Adam     4  0.416667\n",
            "optimizador:\n",
            "Epoch 1/4, Loss: 2.405358485877514\n",
            "Epoch 2/4, Loss: 2.2779505774378777\n",
            "Epoch 3/4, Loss: 2.114347618073225\n",
            "Epoch 4/4, Loss: 1.88254876434803\n",
            "Accuracy on validation set: 0.3409090909090909\n",
            "Evaluacion final\n",
            "epocas: 4\n",
            "batch_size: 8\n",
            "optimizador: Adam\n",
            "Capas: 5\n",
            "Final accuracy on test set: 0.3333333333333333\n",
            "   epocas batch optimizador capas  accuracy\n",
            "0       4     4        Adam     3  0.424242\n",
            "1       4     4        Adam     4  0.310606\n",
            "2       4     4        Adam     5  0.174242\n",
            "3       4     4         SGD     3  0.454545\n",
            "4       4     4         SGD     4  0.090909\n",
            "5       4     4         SGD     5  0.174242\n",
            "6       4     4     Adagrad     3  0.454545\n",
            "7       4     4     Adagrad     4  0.439394\n",
            "8       4     4     Adagrad     5  0.363636\n",
            "9       4     8        Adam     3  0.492424\n",
            "10      4     8        Adam     4  0.416667\n",
            "11      4     8        Adam     5  0.333333\n",
            "optimizador:\n",
            "Epoch 1/4, Loss: 2.36521714925766\n",
            "Epoch 2/4, Loss: 2.170699268579483\n",
            "Epoch 3/4, Loss: 2.015286784619093\n",
            "Epoch 4/4, Loss: 1.84605473279953\n",
            "Accuracy on validation set: 0.36363636363636365\n",
            "Evaluacion final\n",
            "epocas: 4\n",
            "batch_size: 8\n",
            "optimizador: SGD\n",
            "Capas: 3\n",
            "Final accuracy on test set: 0.36363636363636365\n",
            "   epocas batch optimizador capas  accuracy\n",
            "0       4     4        Adam     3  0.424242\n",
            "1       4     4        Adam     4  0.310606\n",
            "2       4     4        Adam     5  0.174242\n",
            "3       4     4         SGD     3  0.454545\n",
            "4       4     4         SGD     4  0.090909\n",
            "5       4     4         SGD     5  0.174242\n",
            "6       4     4     Adagrad     3  0.454545\n",
            "7       4     4     Adagrad     4  0.439394\n",
            "8       4     4     Adagrad     5  0.363636\n",
            "9       4     8        Adam     3  0.492424\n",
            "10      4     8        Adam     4  0.416667\n",
            "11      4     8        Adam     5  0.333333\n",
            "12      4     8         SGD     3  0.363636\n",
            "optimizador:\n",
            "Epoch 1/4, Loss: 2.3987902104854584\n",
            "Epoch 2/4, Loss: 2.395495727658272\n",
            "Epoch 3/4, Loss: 2.390217572450638\n",
            "Epoch 4/4, Loss: 2.3846993669867516\n",
            "Accuracy on validation set: 0.13636363636363635\n",
            "Evaluacion final\n",
            "epocas: 4\n",
            "batch_size: 8\n",
            "optimizador: SGD\n",
            "Capas: 4\n",
            "Final accuracy on test set: 0.12121212121212122\n",
            "   epocas batch optimizador capas  accuracy\n",
            "0       4     4        Adam     3  0.424242\n",
            "1       4     4        Adam     4  0.310606\n",
            "2       4     4        Adam     5  0.174242\n",
            "3       4     4         SGD     3  0.454545\n",
            "4       4     4         SGD     4  0.090909\n",
            "5       4     4         SGD     5  0.174242\n",
            "6       4     4     Adagrad     3  0.454545\n",
            "7       4     4     Adagrad     4  0.439394\n",
            "8       4     4     Adagrad     5  0.363636\n",
            "9       4     8        Adam     3  0.492424\n",
            "10      4     8        Adam     4  0.416667\n",
            "11      4     8        Adam     5  0.333333\n",
            "12      4     8         SGD     3  0.363636\n",
            "13      4     8         SGD     4  0.121212\n",
            "optimizador:\n",
            "Epoch 1/4, Loss: 2.3986466005444527\n",
            "Epoch 2/4, Loss: 2.398125819861889\n",
            "Epoch 3/4, Loss: 2.397798590362072\n",
            "Epoch 4/4, Loss: 2.3969683572649956\n",
            "Accuracy on validation set: 0.10606060606060606\n",
            "Evaluacion final\n",
            "epocas: 4\n",
            "batch_size: 8\n",
            "optimizador: SGD\n",
            "Capas: 5\n",
            "Final accuracy on test set: 0.13636363636363635\n",
            "   epocas batch optimizador capas  accuracy\n",
            "0       4     4        Adam     3  0.424242\n",
            "1       4     4        Adam     4  0.310606\n",
            "2       4     4        Adam     5  0.174242\n",
            "3       4     4         SGD     3  0.454545\n",
            "4       4     4         SGD     4  0.090909\n",
            "5       4     4         SGD     5  0.174242\n",
            "6       4     4     Adagrad     3  0.454545\n",
            "7       4     4     Adagrad     4  0.439394\n",
            "8       4     4     Adagrad     5  0.363636\n",
            "9       4     8        Adam     3  0.492424\n",
            "10      4     8        Adam     4  0.416667\n",
            "11      4     8        Adam     5  0.333333\n",
            "12      4     8         SGD     3  0.363636\n",
            "13      4     8         SGD     4  0.121212\n",
            "14      4     8         SGD     5  0.136364\n",
            "optimizador:\n",
            "Epoch 1/4, Loss: 2.3498032242059708\n",
            "Epoch 2/4, Loss: 1.573768513277173\n",
            "Epoch 3/4, Loss: 1.1452362164855003\n",
            "Epoch 4/4, Loss: 0.7937996434047818\n",
            "Accuracy on validation set: 0.5757575757575758\n",
            "Evaluacion final\n",
            "epocas: 4\n",
            "batch_size: 8\n",
            "optimizador: Adagrad\n",
            "Capas: 3\n",
            "Final accuracy on test set: 0.5757575757575758\n",
            "   epocas batch optimizador capas  accuracy\n",
            "0       4     4        Adam     3  0.424242\n",
            "1       4     4        Adam     4  0.310606\n",
            "2       4     4        Adam     5  0.174242\n",
            "3       4     4         SGD     3  0.454545\n",
            "4       4     4         SGD     4  0.090909\n",
            "5       4     4         SGD     5  0.174242\n",
            "6       4     4     Adagrad     3  0.454545\n",
            "7       4     4     Adagrad     4  0.439394\n",
            "8       4     4     Adagrad     5  0.363636\n",
            "9       4     8        Adam     3  0.492424\n",
            "10      4     8        Adam     4  0.416667\n",
            "11      4     8        Adam     5  0.333333\n",
            "12      4     8         SGD     3  0.363636\n",
            "13      4     8         SGD     4  0.121212\n",
            "14      4     8         SGD     5  0.136364\n",
            "15      4     8     Adagrad     3  0.575758\n",
            "optimizador:\n",
            "Epoch 1/4, Loss: 2.3274580612778664\n",
            "Epoch 2/4, Loss: 1.969887688755989\n",
            "Epoch 3/4, Loss: 1.6176708042621613\n",
            "Epoch 4/4, Loss: 1.3656812757253647\n",
            "Accuracy on validation set: 0.4696969696969697\n",
            "Evaluacion final\n",
            "epocas: 4\n",
            "batch_size: 8\n",
            "optimizador: Adagrad\n",
            "Capas: 4\n",
            "Final accuracy on test set: 0.49242424242424243\n",
            "   epocas batch optimizador capas  accuracy\n",
            "0       4     4        Adam     3  0.424242\n",
            "1       4     4        Adam     4  0.310606\n",
            "2       4     4        Adam     5  0.174242\n",
            "3       4     4         SGD     3  0.454545\n",
            "4       4     4         SGD     4  0.090909\n",
            "5       4     4         SGD     5  0.174242\n",
            "6       4     4     Adagrad     3  0.454545\n",
            "7       4     4     Adagrad     4  0.439394\n",
            "8       4     4     Adagrad     5  0.363636\n",
            "9       4     8        Adam     3  0.492424\n",
            "10      4     8        Adam     4  0.416667\n",
            "11      4     8        Adam     5  0.333333\n",
            "12      4     8         SGD     3  0.363636\n",
            "13      4     8         SGD     4  0.121212\n",
            "14      4     8         SGD     5  0.136364\n",
            "15      4     8     Adagrad     3  0.575758\n",
            "16      4     8     Adagrad     4  0.492424\n",
            "optimizador:\n",
            "Epoch 1/4, Loss: 2.38682559132576\n",
            "Epoch 2/4, Loss: 2.124722633510828\n",
            "Epoch 3/4, Loss: 1.8659552708268166\n",
            "Epoch 4/4, Loss: 1.661073487251997\n",
            "Accuracy on validation set: 0.4166666666666667\n",
            "Evaluacion final\n",
            "epocas: 4\n",
            "batch_size: 8\n",
            "optimizador: Adagrad\n",
            "Capas: 5\n",
            "Final accuracy on test set: 0.4621212121212121\n",
            "   epocas batch optimizador capas  accuracy\n",
            "0       4     4        Adam     3  0.424242\n",
            "1       4     4        Adam     4  0.310606\n",
            "2       4     4        Adam     5  0.174242\n",
            "3       4     4         SGD     3  0.454545\n",
            "4       4     4         SGD     4  0.090909\n",
            "5       4     4         SGD     5  0.174242\n",
            "6       4     4     Adagrad     3  0.454545\n",
            "7       4     4     Adagrad     4  0.439394\n",
            "8       4     4     Adagrad     5  0.363636\n",
            "9       4     8        Adam     3  0.492424\n",
            "10      4     8        Adam     4  0.416667\n",
            "11      4     8        Adam     5  0.333333\n",
            "12      4     8         SGD     3  0.363636\n",
            "13      4     8         SGD     4  0.121212\n",
            "14      4     8         SGD     5  0.136364\n",
            "15      4     8     Adagrad     3  0.575758\n",
            "16      4     8     Adagrad     4  0.492424\n",
            "17      4     8     Adagrad     5  0.462121\n",
            "optimizador:\n",
            "Epoch 1/4, Loss: 2.9314363327893345\n",
            "Epoch 2/4, Loss: 1.917103480209004\n",
            "Epoch 3/4, Loss: 1.51969962016764\n",
            "Epoch 4/4, Loss: 1.2038983377543362\n",
            "Accuracy on validation set: 0.5303030303030303\n",
            "Evaluacion final\n",
            "epocas: 4\n",
            "batch_size: 12\n",
            "optimizador: Adam\n",
            "Capas: 3\n",
            "Final accuracy on test set: 0.5378787878787878\n",
            "   epocas batch optimizador capas  accuracy\n",
            "0       4     4        Adam     3  0.424242\n",
            "1       4     4        Adam     4  0.310606\n",
            "2       4     4        Adam     5  0.174242\n",
            "3       4     4         SGD     3  0.454545\n",
            "4       4     4         SGD     4  0.090909\n",
            "5       4     4         SGD     5  0.174242\n",
            "6       4     4     Adagrad     3  0.454545\n",
            "7       4     4     Adagrad     4  0.439394\n",
            "8       4     4     Adagrad     5  0.363636\n",
            "9       4     8        Adam     3  0.492424\n",
            "10      4     8        Adam     4  0.416667\n",
            "11      4     8        Adam     5  0.333333\n",
            "12      4     8         SGD     3  0.363636\n",
            "13      4     8         SGD     4  0.121212\n",
            "14      4     8         SGD     5  0.136364\n",
            "15      4     8     Adagrad     3  0.575758\n",
            "16      4     8     Adagrad     4  0.492424\n",
            "17      4     8     Adagrad     5  0.462121\n",
            "18      4    12        Adam     3  0.537879\n",
            "optimizador:\n",
            "Epoch 1/4, Loss: 2.301391802050851\n",
            "Epoch 2/4, Loss: 1.923948190428994\n",
            "Epoch 3/4, Loss: 1.4677512103861028\n",
            "Epoch 4/4, Loss: 1.478040879422968\n",
            "Accuracy on validation set: 0.3939393939393939\n",
            "Evaluacion final\n",
            "epocas: 4\n",
            "batch_size: 12\n",
            "optimizador: Adam\n",
            "Capas: 4\n",
            "Final accuracy on test set: 0.4393939393939394\n",
            "   epocas batch optimizador capas  accuracy\n",
            "0       4     4        Adam     3  0.424242\n",
            "1       4     4        Adam     4  0.310606\n",
            "2       4     4        Adam     5  0.174242\n",
            "3       4     4         SGD     3  0.454545\n",
            "4       4     4         SGD     4  0.090909\n",
            "5       4     4         SGD     5  0.174242\n",
            "6       4     4     Adagrad     3  0.454545\n",
            "7       4     4     Adagrad     4  0.439394\n",
            "8       4     4     Adagrad     5  0.363636\n",
            "9       4     8        Adam     3  0.492424\n",
            "10      4     8        Adam     4  0.416667\n",
            "11      4     8        Adam     5  0.333333\n",
            "12      4     8         SGD     3  0.363636\n",
            "13      4     8         SGD     4  0.121212\n",
            "14      4     8         SGD     5  0.136364\n",
            "15      4     8     Adagrad     3  0.575758\n",
            "16      4     8     Adagrad     4  0.492424\n",
            "17      4     8     Adagrad     5  0.462121\n",
            "18      4    12        Adam     3  0.537879\n",
            "19      4    12        Adam     4  0.439394\n",
            "optimizador:\n",
            "Epoch 1/4, Loss: 2.4088540293953637\n",
            "Epoch 2/4, Loss: 2.2479677308689463\n",
            "Epoch 3/4, Loss: 2.010682859204032\n",
            "Epoch 4/4, Loss: 1.7875779812986201\n",
            "Accuracy on validation set: 0.3333333333333333\n",
            "Evaluacion final\n",
            "epocas: 4\n",
            "batch_size: 12\n",
            "optimizador: Adam\n",
            "Capas: 5\n",
            "Final accuracy on test set: 0.3712121212121212\n",
            "   epocas batch optimizador capas  accuracy\n",
            "0       4     4        Adam     3  0.424242\n",
            "1       4     4        Adam     4  0.310606\n",
            "2       4     4        Adam     5  0.174242\n",
            "3       4     4         SGD     3  0.454545\n",
            "4       4     4         SGD     4  0.090909\n",
            "5       4     4         SGD     5  0.174242\n",
            "6       4     4     Adagrad     3  0.454545\n",
            "7       4     4     Adagrad     4  0.439394\n",
            "8       4     4     Adagrad     5  0.363636\n",
            "9       4     8        Adam     3  0.492424\n",
            "10      4     8        Adam     4  0.416667\n",
            "11      4     8        Adam     5  0.333333\n",
            "12      4     8         SGD     3  0.363636\n",
            "13      4     8         SGD     4  0.121212\n",
            "14      4     8         SGD     5  0.136364\n",
            "15      4     8     Adagrad     3  0.575758\n",
            "16      4     8     Adagrad     4  0.492424\n",
            "17      4     8     Adagrad     5  0.462121\n",
            "18      4    12        Adam     3  0.537879\n",
            "19      4    12        Adam     4  0.439394\n",
            "20      4    12        Adam     5  0.371212\n",
            "optimizador:\n",
            "Epoch 1/4, Loss: 2.3741612867875532\n",
            "Epoch 2/4, Loss: 2.334803245284341\n",
            "Epoch 3/4, Loss: 2.23114229332317\n",
            "Epoch 4/4, Loss: 2.0323846990411933\n",
            "Accuracy on validation set: 0.25\n",
            "Evaluacion final\n",
            "epocas: 4\n",
            "batch_size: 12\n",
            "optimizador: SGD\n",
            "Capas: 3\n",
            "Final accuracy on test set: 0.24242424242424243\n",
            "   epocas batch optimizador capas  accuracy\n",
            "0       4     4        Adam     3  0.424242\n",
            "1       4     4        Adam     4  0.310606\n",
            "2       4     4        Adam     5  0.174242\n",
            "3       4     4         SGD     3  0.454545\n",
            "4       4     4         SGD     4  0.090909\n",
            "5       4     4         SGD     5  0.174242\n",
            "6       4     4     Adagrad     3  0.454545\n",
            "7       4     4     Adagrad     4  0.439394\n",
            "8       4     4     Adagrad     5  0.363636\n",
            "9       4     8        Adam     3  0.492424\n",
            "10      4     8        Adam     4  0.416667\n",
            "11      4     8        Adam     5  0.333333\n",
            "12      4     8         SGD     3  0.363636\n",
            "13      4     8         SGD     4  0.121212\n",
            "14      4     8         SGD     5  0.136364\n",
            "15      4     8     Adagrad     3  0.575758\n",
            "16      4     8     Adagrad     4  0.492424\n",
            "17      4     8     Adagrad     5  0.462121\n",
            "18      4    12        Adam     3  0.537879\n",
            "19      4    12        Adam     4  0.439394\n",
            "20      4    12        Adam     5  0.371212\n",
            "21      4    12         SGD     3  0.242424\n",
            "optimizador:\n",
            "Epoch 1/4, Loss: 2.3973944078792226\n",
            "Epoch 2/4, Loss: 2.3948931152170356\n",
            "Epoch 3/4, Loss: 2.3938026319850576\n",
            "Epoch 4/4, Loss: 2.3908596363934604\n",
            "Accuracy on validation set: 0.20454545454545456\n",
            "Evaluacion final\n",
            "epocas: 4\n",
            "batch_size: 12\n",
            "optimizador: SGD\n",
            "Capas: 4\n",
            "Final accuracy on test set: 0.21212121212121213\n",
            "   epocas batch optimizador capas  accuracy\n",
            "0       4     4        Adam     3  0.424242\n",
            "1       4     4        Adam     4  0.310606\n",
            "2       4     4        Adam     5  0.174242\n",
            "3       4     4         SGD     3  0.454545\n",
            "4       4     4         SGD     4  0.090909\n",
            "5       4     4         SGD     5  0.174242\n",
            "6       4     4     Adagrad     3  0.454545\n",
            "7       4     4     Adagrad     4  0.439394\n",
            "8       4     4     Adagrad     5  0.363636\n",
            "9       4     8        Adam     3  0.492424\n",
            "10      4     8        Adam     4  0.416667\n",
            "11      4     8        Adam     5  0.333333\n",
            "12      4     8         SGD     3  0.363636\n",
            "13      4     8         SGD     4  0.121212\n",
            "14      4     8         SGD     5  0.136364\n",
            "15      4     8     Adagrad     3  0.575758\n",
            "16      4     8     Adagrad     4  0.492424\n",
            "17      4     8     Adagrad     5  0.462121\n",
            "18      4    12        Adam     3  0.537879\n",
            "19      4    12        Adam     4  0.439394\n",
            "20      4    12        Adam     5  0.371212\n",
            "21      4    12         SGD     3  0.242424\n",
            "22      4    12         SGD     4  0.212121\n",
            "optimizador:\n",
            "Epoch 1/4, Loss: 2.4007595127279107\n",
            "Epoch 2/4, Loss: 2.3972702026367188\n",
            "Epoch 3/4, Loss: 2.3984489007429644\n",
            "Epoch 4/4, Loss: 2.397340763698925\n",
            "Accuracy on validation set: 0.09848484848484848\n",
            "Evaluacion final\n",
            "epocas: 4\n",
            "batch_size: 12\n",
            "optimizador: SGD\n",
            "Capas: 5\n",
            "Final accuracy on test set: 0.10606060606060606\n",
            "   epocas batch optimizador capas  accuracy\n",
            "0       4     4        Adam     3  0.424242\n",
            "1       4     4        Adam     4  0.310606\n",
            "2       4     4        Adam     5  0.174242\n",
            "3       4     4         SGD     3  0.454545\n",
            "4       4     4         SGD     4  0.090909\n",
            "5       4     4         SGD     5  0.174242\n",
            "6       4     4     Adagrad     3  0.454545\n",
            "7       4     4     Adagrad     4  0.439394\n",
            "8       4     4     Adagrad     5  0.363636\n",
            "9       4     8        Adam     3  0.492424\n",
            "10      4     8        Adam     4  0.416667\n",
            "11      4     8        Adam     5  0.333333\n",
            "12      4     8         SGD     3  0.363636\n",
            "13      4     8         SGD     4  0.121212\n",
            "14      4     8         SGD     5  0.136364\n",
            "15      4     8     Adagrad     3  0.575758\n",
            "16      4     8     Adagrad     4  0.492424\n",
            "17      4     8     Adagrad     5  0.462121\n",
            "18      4    12        Adam     3  0.537879\n",
            "19      4    12        Adam     4  0.439394\n",
            "20      4    12        Adam     5  0.371212\n",
            "21      4    12         SGD     3  0.242424\n",
            "22      4    12         SGD     4  0.212121\n",
            "23      4    12         SGD     5  0.106061\n",
            "optimizador:\n",
            "Epoch 1/4, Loss: 2.395545108751817\n",
            "Epoch 2/4, Loss: 1.5886302888393402\n",
            "Epoch 3/4, Loss: 1.2686562402681871\n",
            "Epoch 4/4, Loss: 0.9341697901148688\n",
            "Accuracy on validation set: 0.5454545454545454\n",
            "Evaluacion final\n",
            "epocas: 4\n",
            "batch_size: 12\n",
            "optimizador: Adagrad\n",
            "Capas: 3\n",
            "Final accuracy on test set: 0.5757575757575758\n",
            "   epocas batch optimizador capas  accuracy\n",
            "0       4     4        Adam     3  0.424242\n",
            "1       4     4        Adam     4  0.310606\n",
            "2       4     4        Adam     5  0.174242\n",
            "3       4     4         SGD     3  0.454545\n",
            "4       4     4         SGD     4  0.090909\n",
            "5       4     4         SGD     5  0.174242\n",
            "6       4     4     Adagrad     3  0.454545\n",
            "7       4     4     Adagrad     4  0.439394\n",
            "8       4     4     Adagrad     5  0.363636\n",
            "9       4     8        Adam     3  0.492424\n",
            "10      4     8        Adam     4  0.416667\n",
            "11      4     8        Adam     5  0.333333\n",
            "12      4     8         SGD     3  0.363636\n",
            "13      4     8         SGD     4  0.121212\n",
            "14      4     8         SGD     5  0.136364\n",
            "15      4     8     Adagrad     3  0.575758\n",
            "16      4     8     Adagrad     4  0.492424\n",
            "17      4     8     Adagrad     5  0.462121\n",
            "18      4    12        Adam     3  0.537879\n",
            "19      4    12        Adam     4  0.439394\n",
            "20      4    12        Adam     5  0.371212\n",
            "21      4    12         SGD     3  0.242424\n",
            "22      4    12         SGD     4  0.212121\n",
            "23      4    12         SGD     5  0.106061\n",
            "24      4    12     Adagrad     3  0.575758\n",
            "optimizador:\n",
            "Epoch 1/4, Loss: 2.354573271491311\n",
            "Epoch 2/4, Loss: 2.0242369771003723\n",
            "Epoch 3/4, Loss: 1.6635340723124417\n",
            "Epoch 4/4, Loss: 1.398826691237363\n",
            "Accuracy on validation set: 0.3181818181818182\n",
            "Evaluacion final\n",
            "epocas: 4\n",
            "batch_size: 12\n",
            "optimizador: Adagrad\n",
            "Capas: 4\n",
            "Final accuracy on test set: 0.2878787878787879\n",
            "   epocas batch optimizador capas  accuracy\n",
            "0       4     4        Adam     3  0.424242\n",
            "1       4     4        Adam     4  0.310606\n",
            "2       4     4        Adam     5  0.174242\n",
            "3       4     4         SGD     3  0.454545\n",
            "4       4     4         SGD     4  0.090909\n",
            "5       4     4         SGD     5  0.174242\n",
            "6       4     4     Adagrad     3  0.454545\n",
            "7       4     4     Adagrad     4  0.439394\n",
            "8       4     4     Adagrad     5  0.363636\n",
            "9       4     8        Adam     3  0.492424\n",
            "10      4     8        Adam     4  0.416667\n",
            "11      4     8        Adam     5  0.333333\n",
            "12      4     8         SGD     3  0.363636\n",
            "13      4     8         SGD     4  0.121212\n",
            "14      4     8         SGD     5  0.136364\n",
            "15      4     8     Adagrad     3  0.575758\n",
            "16      4     8     Adagrad     4  0.492424\n",
            "17      4     8     Adagrad     5  0.462121\n",
            "18      4    12        Adam     3  0.537879\n",
            "19      4    12        Adam     4  0.439394\n",
            "20      4    12        Adam     5  0.371212\n",
            "21      4    12         SGD     3  0.242424\n",
            "22      4    12         SGD     4  0.212121\n",
            "23      4    12         SGD     5  0.106061\n",
            "24      4    12     Adagrad     3  0.575758\n",
            "25      4    12     Adagrad     4  0.287879\n",
            "optimizador:\n",
            "Epoch 1/4, Loss: 2.4563373869115654\n",
            "Epoch 2/4, Loss: 2.2750723416155036\n",
            "Epoch 3/4, Loss: 2.1826050118966536\n",
            "Epoch 4/4, Loss: 2.050602522763339\n",
            "Accuracy on validation set: 0.25757575757575757\n",
            "Evaluacion final\n",
            "epocas: 4\n",
            "batch_size: 12\n",
            "optimizador: Adagrad\n",
            "Capas: 5\n",
            "Final accuracy on test set: 0.2803030303030303\n",
            "   epocas batch optimizador capas  accuracy\n",
            "0       4     4        Adam     3  0.424242\n",
            "1       4     4        Adam     4  0.310606\n",
            "2       4     4        Adam     5  0.174242\n",
            "3       4     4         SGD     3  0.454545\n",
            "4       4     4         SGD     4  0.090909\n",
            "5       4     4         SGD     5  0.174242\n",
            "6       4     4     Adagrad     3  0.454545\n",
            "7       4     4     Adagrad     4  0.439394\n",
            "8       4     4     Adagrad     5  0.363636\n",
            "9       4     8        Adam     3  0.492424\n",
            "10      4     8        Adam     4  0.416667\n",
            "11      4     8        Adam     5  0.333333\n",
            "12      4     8         SGD     3  0.363636\n",
            "13      4     8         SGD     4  0.121212\n",
            "14      4     8         SGD     5  0.136364\n",
            "15      4     8     Adagrad     3  0.575758\n",
            "16      4     8     Adagrad     4  0.492424\n",
            "17      4     8     Adagrad     5  0.462121\n",
            "18      4    12        Adam     3  0.537879\n",
            "19      4    12        Adam     4  0.439394\n",
            "20      4    12        Adam     5  0.371212\n",
            "21      4    12         SGD     3  0.242424\n",
            "22      4    12         SGD     4  0.212121\n",
            "23      4    12         SGD     5  0.106061\n",
            "24      4    12     Adagrad     3  0.575758\n",
            "25      4    12     Adagrad     4  0.287879\n",
            "26      4    12     Adagrad     5  0.280303\n"
          ]
        }
      ],
      "source": [
        "for epochs_ind in range(len(epochs)):\n",
        "  for batch_ind in range(len(batch_size)):\n",
        "    for opt_ind in range(len(optimizador)):\n",
        "      for capas_ind in range(len(capas)):\n",
        "\n",
        "\n",
        "          # Red neuronal\n",
        "          class CNNWeatherClassifier3(nn.Module):\n",
        "              def __init__(self, num_classes):\n",
        "                  super(CNNWeatherClassifier3, self).__init__()\n",
        "                  self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "                  self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "                  self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "                  self.pool = nn.MaxPool2d(2, 2)\n",
        "                  self.fc1 = nn.Linear(64 * 28 * 28, 512)\n",
        "                  self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "              def forward(self, x):\n",
        "                  x = self.pool(torch.relu(self.conv1(x)))\n",
        "                  x = self.pool(torch.relu(self.conv2(x)))\n",
        "                  x = self.pool(torch.relu(self.conv3(x)))\n",
        "                  x = torch.flatten(x, 1)\n",
        "                  x = torch.relu(self.fc1(x))\n",
        "                  x = self.fc2(x)\n",
        "                  return x\n",
        "\n",
        "\n",
        "          class CNNWeatherClassifier4(nn.Module):\n",
        "              def __init__(self, num_classes):\n",
        "                  super(CNNWeatherClassifier4, self).__init__()\n",
        "                  self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "                  self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "                  self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "                  self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "                  self.pool = nn.MaxPool2d(2, 2)\n",
        "                  self.fc1 = nn.Linear(128 * 14 * 14, 512)\n",
        "                  self.fc2 = nn.Linear(512, 256)\n",
        "                  self.fc3 = nn.Linear(256, num_classes)\n",
        "\n",
        "              def forward(self, x):\n",
        "                  x = self.pool(torch.relu(self.conv1(x)))\n",
        "                  x = self.pool(torch.relu(self.conv2(x)))\n",
        "                  x = self.pool(torch.relu(self.conv3(x)))\n",
        "                  x = self.pool(torch.relu(self.conv4(x)))\n",
        "                  x = torch.flatten(x, 1)\n",
        "                  x = torch.relu(self.fc1(x))\n",
        "                  x = torch.relu(self.fc2(x))\n",
        "                  x = self.fc3(x)\n",
        "                  return x\n",
        "\n",
        "\n",
        "          class CNNWeatherClassifier5(nn.Module):\n",
        "            def __init__(self, num_classes):\n",
        "                super(CNNWeatherClassifier5, self).__init__()\n",
        "                self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "                self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "                self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "                self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "                self.conv5 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "                self.pool = nn.MaxPool2d(2, 2)\n",
        "                self.fc1 = nn.Linear(256 * 7 * 7, 512)\n",
        "                self.fc2 = nn.Linear(512, 256)\n",
        "                self.fc3 = nn.Linear(256, num_classes)\n",
        "\n",
        "            def forward(self, x):\n",
        "                x = self.pool(torch.relu(self.conv1(x)))\n",
        "                x = self.pool(torch.relu(self.conv2(x)))\n",
        "                x = self.pool(torch.relu(self.conv3(x)))\n",
        "                x = self.pool(torch.relu(self.conv4(x)))\n",
        "                x = self.pool(torch.relu(self.conv5(x)))\n",
        "                x = torch.flatten(x, 1)\n",
        "                x = torch.relu(self.fc1(x))\n",
        "                x = torch.relu(self.fc2(x))\n",
        "                x = self.fc3(x)\n",
        "                return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "          train_loader = DataLoader(train_dataset, batch_size=batch_size[batch_ind], shuffle=True)\n",
        "          valid_loader = DataLoader(valid_dataset, batch_size=batch_size[batch_ind], shuffle=False)\n",
        "          test_loader = DataLoader(test_dataset, batch_size=batch_size[batch_ind], shuffle=False)\n",
        "\n",
        "\n",
        "\n",
        "          #instancia del modelo\n",
        "          if(capas[capas_ind]==3):\n",
        "            model = CNNWeatherClassifier3(num_classes=len(train_dataset.classes))\n",
        "          elif(capas[capas_ind]==4):\n",
        "            model = CNNWeatherClassifier4(num_classes=len(train_dataset.classes))\n",
        "          else:\n",
        "            model = CNNWeatherClassifier5(num_classes=len(train_dataset.classes))\n",
        "\n",
        "\n",
        "\n",
        "          #funcion de perdida y optimizador\n",
        "          criterion = nn.CrossEntropyLoss()\n",
        "          print(\"optimizador:\")\n",
        "          if(optimizador[opt_ind]==\"SGD\"):\n",
        "            optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "          elif(optimizador[opt_ind]==\"Adam\"):\n",
        "            optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "          else:\n",
        "            optimizer = optim.Adagrad(model.parameters(), lr=0.001)\n",
        "\n",
        "          #entrenar el modelo\n",
        "\n",
        "          for epoch in range(epochs[epochs_ind]):\n",
        "              model.train()\n",
        "              running_loss = 0.0\n",
        "              for images, labels in train_loader:\n",
        "                  optimizer.zero_grad()\n",
        "                  outputs = model(images)\n",
        "                  loss = criterion(outputs, labels)\n",
        "                  loss.backward()\n",
        "                  optimizer.step()\n",
        "                  running_loss += loss.item()\n",
        "              print(f\"Epoch {epoch+1}/{epochs[epochs_ind]}, Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "\n",
        "          #evaluar el modelo en el conjunto de validacion\n",
        "          model.eval()\n",
        "          correct = 0\n",
        "          total = 0\n",
        "          with torch.no_grad():\n",
        "              for images, labels in valid_loader:\n",
        "                  outputs = model(images)\n",
        "                  _, predicted = torch.max(outputs, 1)\n",
        "                  total += labels.size(0)\n",
        "                  correct += (predicted == labels).sum().item()\n",
        "\n",
        "          accuracy = correct / total\n",
        "          print(f\"Accuracy on validation set: {accuracy}\")\n",
        "\n",
        "\n",
        "          #evaluacion final en el conjunto de test\n",
        "          correct = 0\n",
        "          total = 0\n",
        "          with torch.no_grad():\n",
        "              for images, labels in test_loader:\n",
        "                  outputs = model(images)\n",
        "                  _, predicted = torch.max(outputs, 1)\n",
        "                  total += labels.size(0)\n",
        "                  correct += (predicted == labels).sum().item()\n",
        "\n",
        "          accuracy = correct / total\n",
        "          print(\"Evaluacion final\")\n",
        "          print(\"epocas:\",str(epochs[epochs_ind]))\n",
        "          print(\"batch_size:\",str(batch_size[batch_ind]))\n",
        "          print(\"optimizador:\",str(optimizador[opt_ind]))\n",
        "          print(\"Capas:\",str(capas[capas_ind]))\n",
        "\n",
        "          print(f\"Final accuracy on test set: {accuracy}\")\n",
        "          dfError.loc[len(dfError)] = [str(epochs[epochs_ind]),str(batch_size[batch_ind]),str(optimizador[opt_ind]), str(capas[capas_ind]), accuracy]\n",
        "          print(dfError)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "u-_8j74rXzMX"
      },
      "outputs": [],
      "source": [
        "dfError.to_csv('/content/drive/MyDrive/Colab Notebooks/erroresPyTorch.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}